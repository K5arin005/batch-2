import pandas as pd
import re
import string
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from nltk.corpus import stopwords
import nltk

# Download NLTK data (run only once)
nltk.download('stopwords')

# Load dataset
import pandas as pd

# **Update the path to the correct location of your file**
df = pd.read_csv('/content/drive/MyDrive/sentimentdataset (1).csv')  

# Print the column names to inspect them
print(df.columns)

# Assuming the sentiment label is in a column named 'sentiment'
# Rename the column to 'label'
if 'sentiment' in df.columns:  # Check if 'sentiment' column exists
    df = df.rename(columns={'sentiment': 'label'})
elif 'Sentiment' in df.columns:  # Check if 'Sentiment' column exists
    df = df.rename(columns={'Sentiment': 'label'})
# Add more elif blocks if you suspect other potential column names

# Basic data inspection
print("Dataset preview:")
print(df.head())
print("\nClass distribution:")
print(df['label'].value_counts())

